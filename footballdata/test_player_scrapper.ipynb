{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import leagues, LEAGUE_URL\n",
    "from library import get_season_years\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "# ++-------\n",
    "players = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "\n",
    "for year in range(2010, 2022):\n",
    "    season = get_season_years(year)\n",
    "    for country in leagues:\n",
    "        for tier in leagues[country]:\n",
    "            league_id = leagues[country][tier][\"id\"]\n",
    "            url = LEAGUE_URL.format(leagues[country][tier][\"id\"], season)\n",
    "            urls.append(f\"{url}stats/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import requests\n",
    "# from time import sleep\n",
    "\n",
    "\n",
    "# def scrape_players(urls, players):\n",
    "#     from selenium import webdriver\n",
    "#     from bs4 import BeautifulSoup\n",
    "#     options = webdriver.ChromeOptions()\n",
    "#     failed_urls = []\n",
    "#     no_nationality = []\n",
    "#     no_position = []\n",
    "#     no_yob = []\n",
    "#     options.add_argument('--headless')\n",
    "#     options.add_argument('--disable-gpu')\n",
    "#     driver = webdriver.Chrome(chrome_options=options) # \"/usr/lib/chromium-browser/chromedriver\")\n",
    "\n",
    "\n",
    "#     for url in urls:\n",
    "#         response = requests.head(url)\n",
    "#         if not response.status_code == 200:\n",
    "#             print(f\"{url} does not exist.\")\n",
    "#             print(response.status_code)\n",
    "#             failed_urls.append(url)\n",
    "#             continue\n",
    "#         else:\n",
    "#             print(f\"{'='*20}\\nscraping data from {url}\\n{'='*20}\")\n",
    "\n",
    "#         # load the page and wait for the table to load\n",
    "#         driver.get(url)\n",
    "#         driver.implicitly_wait(10)\n",
    "\n",
    "#         # get the page source\n",
    "#         html_document = driver.page_source\n",
    "\n",
    "#         # parse the page source with BeautifulSoup\n",
    "#         soup = BeautifulSoup(html_document, 'html.parser')\n",
    "\n",
    "#         # find the table with id \"stats_standard\"\n",
    "#         standard_table = soup.find(\"table\", id=\"stats_standard\")\n",
    "\n",
    "#         if not standard_table:\n",
    "#             print(f\"{url} without standard table\")\n",
    "#             continue\n",
    "\n",
    "#         for tr in standard_table.find_all('tr'):\n",
    "#             tds = tr.find_all('td')\n",
    "#             for td in tds:\n",
    "#                 if not td.has_attr(\"data-stat\"):\n",
    "#                     print(f\"No data stat row in this tr, skipping row\")\n",
    "#                     continue\n",
    "#                 # Name URL and ID\n",
    "#                 if td[\"data-stat\"] == \"player\":\n",
    "#                     a_tag = td.find(\"a\")\n",
    "#                     # if not a_tag:\n",
    "#                     #     print(f\"No a_tag for that player, skipping player\")\n",
    "#                     #     continue\n",
    "#                     player_name = a_tag.string\n",
    "#                     player_name = player_name.replace(\" \", \"-\")\n",
    "#                     if player_name in players:\n",
    "#                         print(f\"{player_name} Exists\")\n",
    "#                         continue\n",
    "#                     player_url = a_tag[\"href\"]\n",
    "#                     players[player_name] = {\"id\": player_url.split(\"/\")[3], \"url\": player_url}\n",
    "#                 # Nationality\n",
    "#                 if td[\"data-stat\"] == \"nationality\":\n",
    "#                     a_tag = td.find(\"a\")\n",
    "#                     if not a_tag:\n",
    "#                         print(f\"No a_tag for {player_name} Nationality, skipping Nationality\")\n",
    "#                         no_nationality.append(player_name)\n",
    "#                     else:\n",
    "#                         nationality = a_tag.find(\"span\").find(\"span\")\n",
    "#                         if not nationality:\n",
    "#                             print(f\"No nationality data for {player_name} Nationality, skipping Nationality\")\n",
    "#                             no_nationality.append(player_name)\n",
    "#                         else:\n",
    "#                             nationality = nationality.string\n",
    "#                             players[player_name][\"nationality\"] = [nationality]\n",
    "#                 # Position\n",
    "#                 if td[\"data-stat\"] == \"position\":\n",
    "#                     position = td.string\n",
    "#                     if not position:\n",
    "#                         print(f\"No position data found for {player_name}, skipping Position\")\n",
    "#                         no_position.append(player_name)\n",
    "#                     else:\n",
    "#                         players[player_name][\"position\"] = [position.split(\",\")]\n",
    "\n",
    "#                 # Year of Birth\n",
    "#                 if td[\"data-stat\"] == \"birth_year\":\n",
    "#                     birth_year = td.string\n",
    "#                     if not birth_year:\n",
    "#                         print(f\"No birth_year found for {player_name}, going to next player\")\n",
    "#                         no_yob.append(player_name)\n",
    "#                     else:\n",
    "#                         players[player_name][\"birth_year\"] = int(birth_year)\n",
    "#     driver.close()\n",
    "#     return {\"players_dict\": players, \"failed_urls\": failed_urls, \"no_nationality\": no_nationality, \"no_position\": no_position, \"no_yob\": no_yob}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from settings import players\n",
    "players = players_info.get(\"players_dict\").copy()\n",
    "for player_name in players:\n",
    "    pl_url = players[player_name].get(\"id\")\n",
    "    if not pl_url:\n",
    "        continue\n",
    "\n",
    "    id = pl_url.split(\"/\")[3]\n",
    "    players[player_name][\"id\"] = id\n",
    "\n",
    "    if not players[player_name].get(\"position\"):\n",
    "        continue\n",
    "    players[player_name][\"position\"] = players[player_name][\"position\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: When the response status is 429 only then wait for an hour.\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def check_status_code(url: str) -> int:\n",
    "    response = requests.head(url)\n",
    "    if response.status_code != 200:\n",
    "        if response.status_code == 429:\n",
    "            time.sleep(3600 / 2)  # wait for half an hour\n",
    "            response = requests.head(url)\n",
    "        return response.status_code\n",
    "    return 200\n",
    "\n",
    "\n",
    "def scrape_players(\n",
    "    urls: list, players: Dict, request_interval=30, max_requests=20\n",
    ") -> Dict:\n",
    "    from selenium import webdriver\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    failed_urls = []\n",
    "    no_nationality = []\n",
    "    no_position = []\n",
    "    no_yob = []\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    driver = webdriver.Chrome(\n",
    "        chrome_options=options\n",
    "    )  # \"/usr/lib/chromium-browser/chromedriver\")\n",
    "\n",
    "    # Do only 20 requests then wait 30s\n",
    "    request_count = 0\n",
    "    for url in urls:\n",
    "        status_code = check_status_code(url)\n",
    "        if status_code != 200:\n",
    "            print(f\"{url} does not exist. Status code: {status_code}\")\n",
    "            failed_urls.append(url)\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"{'='*40}\\nscraping data from {url}\\n{'='*40}\")\n",
    "            request_count += 1\n",
    "            if request_count == max_requests:\n",
    "                time.sleep(request_interval)\n",
    "                request_count = 0\n",
    "        try:\n",
    "            # load the page and wait for the table to load\n",
    "            driver.get(url)\n",
    "            driver.implicitly_wait(10)\n",
    "\n",
    "            # get the page source\n",
    "            html_document = driver.page_source\n",
    "\n",
    "            # parse the page source with BeautifulSoup\n",
    "            soup = BeautifulSoup(html_document, \"html.parser\")\n",
    "\n",
    "            # find the table with id \"stats_standard\"\n",
    "            standard_table = soup.find(\"table\", id=\"stats_standard\")\n",
    "\n",
    "            if not standard_table:\n",
    "                print(f\"{url} without standard table\")\n",
    "                continue\n",
    "\n",
    "            for tr in standard_table.find_all(\"tr\"):\n",
    "                tds = tr.find_all(\"td\")\n",
    "                for td in tds:\n",
    "                    if not td.has_attr(\"data-stat\"):\n",
    "                        print(f\"No data stat row in this tr, skipping row\")\n",
    "                        continue\n",
    "                    # Name URL and ID\n",
    "                    if td[\"data-stat\"] == \"player\":\n",
    "                        a_tag = td.find(\"a\")\n",
    "                        player_name = a_tag.string\n",
    "                        player_name = player_name.replace(\" \", \"-\")\n",
    "                        if player_name in players:\n",
    "                            print(f\"{player_name} Exists\")\n",
    "                            continue\n",
    "                        player_url = a_tag[\"href\"]\n",
    "                        players[player_name] = {\n",
    "                            \"id\": player_url.split(\"/\")[3],\n",
    "                            \"url\": player_url,\n",
    "                        }\n",
    "                    # Nationality\n",
    "                    if td[\"data-stat\"] == \"nationality\":\n",
    "                        a_tag = td.find(\"a\")\n",
    "                        if not a_tag:\n",
    "                            print(\n",
    "                                f\"No a_tag for {player_name} Nationality, skipping Nationality\"\n",
    "                            )\n",
    "                            no_nationality.append(player_name)\n",
    "                        else:\n",
    "                            nationality = a_tag.find(\"span\").find(\"span\")\n",
    "                            if not nationality:\n",
    "                                print(\n",
    "                                    f\"No nationality data for {player_name} Nationality, skipping Nationality\"\n",
    "                                )\n",
    "                                no_nationality.append(player_name)\n",
    "                            else:\n",
    "                                nationality = nationality.string\n",
    "                                players[player_name][\"nationality\"] = [nationality]\n",
    "                    # Position\n",
    "                    if td[\"data-stat\"] == \"position\":\n",
    "                        position = td.string\n",
    "                        if not position:\n",
    "                            print(\n",
    "                                f\"No position data found for {player_name}, skipping Position\"\n",
    "                            )\n",
    "                            no_position.append(player_name)\n",
    "                        else:\n",
    "                            players[player_name][\"position\"] = [position.split(\",\")]\n",
    "\n",
    "                    # Year of Birth\n",
    "                    if td[\"data-stat\"] == \"birth_year\":\n",
    "                        birth_year = td.string\n",
    "                        if not birth_year:\n",
    "                            print(\n",
    "                                f\"No birth_year found for {player_name}, going to next player\"\n",
    "                            )\n",
    "                            no_yob.append(player_name)\n",
    "                        else:\n",
    "                            players[player_name][\"birth_year\"] = int(birth_year)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while scraping {url}: {e}\")\n",
    "    driver.close()\n",
    "    return {\n",
    "        \"players_dict\": players,\n",
    "        \"failed_urls\": failed_urls,\n",
    "        \"no_nationality\": no_nationality,\n",
    "        \"no_position\": no_position,\n",
    "        \"no_yob\": no_yob,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_info = scrape_players(urls=urls, players={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (main, Dec  7 2022, 01:11:44) [GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b219bb25f2983647e3989600558b4c91a838e133b06483909f710a157dc52885"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
